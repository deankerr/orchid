{
  "data": [
    {
      "id": "cf59e549-6141-4393-b073-3cf13b31c187",
      "name": "Lambda | meta-llama/llama-4-scout-17b-16e-instruct",
      "context_length": 1048576,
      "model": {
        "slug": "meta-llama/llama-4-scout",
        "hf_slug": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "updated_at": "2025-05-16T21:16:57.919461+00:00",
        "created_at": "2025-04-05T19:31:59.735804+00:00",
        "hf_updated_at": null,
        "name": "Meta: Llama 4 Scout",
        "short_name": "Llama 4 Scout",
        "author": "meta-llama",
        "description": "Llama 4 Scout 17B Instruct (16E) is a mixture-of-experts (MoE) language model developed by Meta, activating 17 billion parameters out of a total of 109B. It supports native multimodal input (text and image) and multilingual output (text and code) across 12 supported languages. Designed for assistant-style interaction and visual reasoning, Scout uses 16 experts per forward pass and features a context length of 10 million tokens, with a training corpus of ~40 trillion tokens.\n\nBuilt for high efficiency and local or commercial deployment, Llama 4 Scout incorporates early fusion for seamless modality integration. It is instruction-tuned for use in multilingual chat, captioning, and image understanding tasks. Released under the Llama 4 Community License, it was last trained on data up to August 2024 and launched publicly on April 5, 2025.",
        "model_version_group_id": null,
        "context_length": 10000000,
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "has_text_output": true,
        "group": "Llama4",
        "instruct_type": null,
        "default_system": null,
        "default_stops": [],
        "hidden": false,
        "router": null,
        "warning_message": null,
        "permaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
        "reasoning_config": null,
        "features": {}
      },
      "model_variant_slug": "meta-llama/llama-4-scout",
      "model_variant_permaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
      "provider_name": "Lambda",
      "provider_info": {
        "name": "Lambda",
        "displayName": "Lambda",
        "slug": "lambda",
        "baseUrl": "url",
        "dataPolicy": {
          "privacyPolicyURL": "https://lambda.ai/legal/privacy-policy",
          "termsOfServiceURL": "https://lambda.ai/legal/terms-of-service",
          "paidModels": {
            "training": false
          }
        },
        "headquarters": "US",
        "hasChatCompletions": true,
        "hasCompletions": true,
        "isAbortable": false,
        "moderationRequired": false,
        "editors": [],
        "owners": [],
        "isMultipartSupported": true,
        "statusPageUrl": null,
        "byokEnabled": true,
        "icon": {
          "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://lambdalabs.com/&size=256"
        }
      },
      "provider_display_name": "Lambda",
      "provider_model_id": "llama-4-scout-17b-16e-instruct",
      "quantization": "fp8",
      "variant": "standard",
      "is_free": false,
      "can_abort": false,
      "max_prompt_tokens": null,
      "max_completion_tokens": 1048576,
      "max_prompt_images": null,
      "max_tokens_per_image": null,
      "supported_parameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "logit_bias",
        "logprobs",
        "top_logprobs",
        "response_format"
      ],
      "is_byok": false,
      "moderation_required": false,
      "data_policy": {
        "privacyPolicyURL": "https://lambda.ai/legal/privacy-policy",
        "termsOfServiceURL": "https://lambda.ai/legal/terms-of-service",
        "paidModels": {
          "training": false
        },
        "training": false
      },
      "pricing": {
        "prompt": "0.00000008",
        "completion": "0.0000003",
        "image": "0",
        "request": "0",
        "web_search": "0",
        "internal_reasoning": "0",
        "discount": 0
      },
      "variable_pricings": [],
      "is_hidden": false,
      "is_deranked": false,
      "is_disabled": false,
      "supports_tool_parameters": false,
      "supports_reasoning": false,
      "supports_multipart": true,
      "limit_rpm": null,
      "limit_rpd": null,
      "limit_rpm_cf": null,
      "has_completions": false,
      "has_chat_completions": true,
      "features": {
        "supported_parameters": {},
        "supports_document_url": null
      },
      "provider_region": null,
      "stats": {
        "endpoint_id": "cf59e549-6141-4393-b073-3cf13b31c187",
        "p50_throughput": 98.5215,
        "p50_latency": 396,
        "request_count": 60893
      },
      "status": 0
    },
    {
      "id": "9cf05ded-eefe-41b4-8c08-0c6460feffea",
      "name": "DeepInfra | meta-llama/llama-4-scout-17b-16e-instruct",
      "context_length": 327680,
      "model": {
        "slug": "meta-llama/llama-4-scout",
        "hf_slug": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "updated_at": "2025-05-16T21:16:57.919461+00:00",
        "created_at": "2025-04-05T19:31:59.735804+00:00",
        "hf_updated_at": null,
        "name": "Meta: Llama 4 Scout",
        "short_name": "Llama 4 Scout",
        "author": "meta-llama",
        "description": "Llama 4 Scout 17B Instruct (16E) is a mixture-of-experts (MoE) language model developed by Meta, activating 17 billion parameters out of a total of 109B. It supports native multimodal input (text and image) and multilingual output (text and code) across 12 supported languages. Designed for assistant-style interaction and visual reasoning, Scout uses 16 experts per forward pass and features a context length of 10 million tokens, with a training corpus of ~40 trillion tokens.\n\nBuilt for high efficiency and local or commercial deployment, Llama 4 Scout incorporates early fusion for seamless modality integration. It is instruction-tuned for use in multilingual chat, captioning, and image understanding tasks. Released under the Llama 4 Community License, it was last trained on data up to August 2024 and launched publicly on April 5, 2025.",
        "model_version_group_id": null,
        "context_length": 10000000,
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "has_text_output": true,
        "group": "Llama4",
        "instruct_type": null,
        "default_system": null,
        "default_stops": [],
        "hidden": false,
        "router": null,
        "warning_message": null,
        "permaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
        "reasoning_config": null,
        "features": {}
      },
      "model_variant_slug": "meta-llama/llama-4-scout",
      "model_variant_permaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
      "provider_name": "DeepInfra",
      "provider_info": {
        "name": "DeepInfra",
        "displayName": "DeepInfra",
        "slug": "deepinfra",
        "baseUrl": "url",
        "dataPolicy": {
          "privacyPolicyURL": "https://deepinfra.com/privacy",
          "termsOfServiceURL": "https://deepinfra.com/terms",
          "dataPolicyUrl": "https://deepinfra.com/docs/data",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          }
        },
        "headquarters": "US",
        "hasChatCompletions": true,
        "hasCompletions": true,
        "isAbortable": true,
        "moderationRequired": false,
        "editors": [],
        "owners": [],
        "isMultipartSupported": true,
        "statusPageUrl": null,
        "byokEnabled": true,
        "icon": {
          "url": "/images/icons/DeepInfra.webp"
        }
      },
      "provider_display_name": "DeepInfra",
      "provider_model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "quantization": "bf16",
      "variant": "standard",
      "is_free": false,
      "can_abort": true,
      "max_prompt_tokens": null,
      "max_completion_tokens": 16384,
      "max_prompt_images": 1,
      "max_tokens_per_image": 3342,
      "supported_parameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "repetition_penalty",
        "response_format",
        "top_k",
        "seed",
        "min_p"
      ],
      "is_byok": false,
      "moderation_required": false,
      "data_policy": {
        "privacyPolicyURL": "https://deepinfra.com/privacy",
        "termsOfServiceURL": "https://deepinfra.com/terms",
        "dataPolicyUrl": "https://deepinfra.com/docs/data",
        "paidModels": {
          "training": false,
          "retainsPrompts": false
        },
        "training": false,
        "retainsPrompts": false
      },
      "pricing": {
        "prompt": "0.00000008",
        "completion": "0.0000003",
        "image": "0.0003342",
        "request": "0",
        "web_search": "0",
        "internal_reasoning": "0",
        "discount": 0
      },
      "variable_pricings": [],
      "is_hidden": false,
      "is_deranked": false,
      "is_disabled": false,
      "supports_tool_parameters": false,
      "supports_reasoning": false,
      "supports_multipart": true,
      "limit_rpm": null,
      "limit_rpd": null,
      "limit_rpm_cf": null,
      "has_completions": true,
      "has_chat_completions": true,
      "features": {
        "supported_parameters": {},
        "supports_document_url": null
      },
      "provider_region": null,
      "stats": {
        "endpoint_id": "9cf05ded-eefe-41b4-8c08-0c6460feffea",
        "p50_throughput": 39.256,
        "p50_latency": 739.5,
        "request_count": 56439
      },
      "status": 0
    },
    {
      "id": "57309b38-5fb1-4601-a114-8286d54cdf3a",
      "name": "Kluster | meta-llama/llama-4-scout-17b-16e-instruct",
      "context_length": 131072,
      "model": {
        "slug": "meta-llama/llama-4-scout",
        "hf_slug": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "updated_at": "2025-05-16T21:16:57.919461+00:00",
        "created_at": "2025-04-05T19:31:59.735804+00:00",
        "hf_updated_at": null,
        "name": "Meta: Llama 4 Scout",
        "short_name": "Llama 4 Scout",
        "author": "meta-llama",
        "description": "Llama 4 Scout 17B Instruct (16E) is a mixture-of-experts (MoE) language model developed by Meta, activating 17 billion parameters out of a total of 109B. It supports native multimodal input (text and image) and multilingual output (text and code) across 12 supported languages. Designed for assistant-style interaction and visual reasoning, Scout uses 16 experts per forward pass and features a context length of 10 million tokens, with a training corpus of ~40 trillion tokens.\n\nBuilt for high efficiency and local or commercial deployment, Llama 4 Scout incorporates early fusion for seamless modality integration. It is instruction-tuned for use in multilingual chat, captioning, and image understanding tasks. Released under the Llama 4 Community License, it was last trained on data up to August 2024 and launched publicly on April 5, 2025.",
        "model_version_group_id": null,
        "context_length": 10000000,
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "has_text_output": true,
        "group": "Llama4",
        "instruct_type": null,
        "default_system": null,
        "default_stops": [],
        "hidden": false,
        "router": null,
        "warning_message": null,
        "permaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
        "reasoning_config": null,
        "features": {}
      },
      "model_variant_slug": "meta-llama/llama-4-scout",
      "model_variant_permaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
      "provider_name": "Kluster",
      "provider_info": {
        "name": "Kluster",
        "displayName": "kluster.ai",
        "slug": "klusterai",
        "baseUrl": "url",
        "dataPolicy": {
          "termsOfServiceURL": "https://www.kluster.ai/terms-of-use",
          "privacyPolicyURL": "https://www.kluster.ai/privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          }
        },
        "headquarters": "US",
        "hasChatCompletions": true,
        "hasCompletions": false,
        "isAbortable": true,
        "moderationRequired": false,
        "editors": [],
        "owners": [],
        "isMultipartSupported": true,
        "statusPageUrl": null,
        "byokEnabled": true,
        "icon": {
          "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.kluster.ai/&size=256"
        }
      },
      "provider_display_name": "kluster.ai",
      "provider_model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "quantization": null,
      "variant": "standard",
      "is_free": false,
      "can_abort": true,
      "max_prompt_tokens": null,
      "max_completion_tokens": 131072,
      "max_prompt_images": 10,
      "max_tokens_per_image": null,
      "supported_parameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "top_k",
        "repetition_penalty",
        "logit_bias",
        "logprobs",
        "top_logprobs",
        "min_p",
        "seed"
      ],
      "is_byok": false,
      "moderation_required": false,
      "data_policy": {
        "termsOfServiceURL": "https://www.kluster.ai/terms-of-use",
        "privacyPolicyURL": "https://www.kluster.ai/privacy-policy",
        "paidModels": {
          "training": false,
          "retainsPrompts": false
        },
        "training": false,
        "retainsPrompts": false
      },
      "pricing": {
        "prompt": "0.00000008",
        "completion": "0.00000045",
        "image": "0.0005013",
        "request": "0",
        "web_search": "0",
        "internal_reasoning": "0",
        "discount": 0
      },
      "variable_pricings": [],
      "is_hidden": false,
      "is_deranked": false,
      "is_disabled": false,
      "supports_tool_parameters": false,
      "supports_reasoning": false,
      "supports_multipart": true,
      "limit_rpm": null,
      "limit_rpd": null,
      "limit_rpm_cf": null,
      "has_completions": false,
      "has_chat_completions": true,
      "features": {
        "supported_parameters": {},
        "supports_document_url": null
      },
      "provider_region": null,
      "stats": {
        "endpoint_id": "57309b38-5fb1-4601-a114-8286d54cdf3a",
        "p50_throughput": 70.6345,
        "p50_latency": 723,
        "request_count": 42256
      },
      "status": 0
    },
    {
      "id": "1ef8e974-2a93-42d6-9eca-bff18a57e595",
      "name": "Parasail | meta-llama/llama-4-scout-17b-16e-instruct",
      "context_length": 158000,
      "model": {
        "slug": "meta-llama/llama-4-scout",
        "hf_slug": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "updated_at": "2025-05-16T21:16:57.919461+00:00",
        "created_at": "2025-04-05T19:31:59.735804+00:00",
        "hf_updated_at": null,
        "name": "Meta: Llama 4 Scout",
        "short_name": "Llama 4 Scout",
        "author": "meta-llama",
        "description": "Llama 4 Scout 17B Instruct (16E) is a mixture-of-experts (MoE) language model developed by Meta, activating 17 billion parameters out of a total of 109B. It supports native multimodal input (text and image) and multilingual output (text and code) across 12 supported languages. Designed for assistant-style interaction and visual reasoning, Scout uses 16 experts per forward pass and features a context length of 10 million tokens, with a training corpus of ~40 trillion tokens.\n\nBuilt for high efficiency and local or commercial deployment, Llama 4 Scout incorporates early fusion for seamless modality integration. It is instruction-tuned for use in multilingual chat, captioning, and image understanding tasks. Released under the Llama 4 Community License, it was last trained on data up to August 2024 and launched publicly on April 5, 2025.",
        "model_version_group_id": null,
        "context_length": 10000000,
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "has_text_output": true,
        "group": "Llama4",
        "instruct_type": null,
        "default_system": null,
        "default_stops": [],
        "hidden": false,
        "router": null,
        "warning_message": null,
        "permaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
        "reasoning_config": null,
        "features": {}
      },
      "model_variant_slug": "meta-llama/llama-4-scout",
      "model_variant_permaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
      "provider_name": "Parasail",
      "provider_info": {
        "name": "Parasail",
        "displayName": "Parasail",
        "slug": "parasail",
        "baseUrl": "url",
        "dataPolicy": {
          "termsOfServiceURL": "https://www.parasail.io/legal/terms",
          "privacyPolicyURL": "https://www.parasail.io/legal/privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": true
          }
        },
        "headquarters": "US",
        "hasChatCompletions": true,
        "hasCompletions": true,
        "isAbortable": true,
        "moderationRequired": false,
        "editors": [],
        "owners": [],
        "isMultipartSupported": true,
        "statusPageUrl": null,
        "byokEnabled": true,
        "icon": {
          "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.parasail.io/&size=256"
        }
      },
      "provider_display_name": "Parasail",
      "provider_model_id": "parasail-llama-4-scout-instruct",
      "quantization": "fp8",
      "variant": "standard",
      "is_free": false,
      "can_abort": true,
      "max_prompt_tokens": null,
      "max_completion_tokens": 158000,
      "max_prompt_images": 1,
      "max_tokens_per_image": 3342,
      "supported_parameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "presence_penalty",
        "frequency_penalty",
        "repetition_penalty",
        "top_k"
      ],
      "is_byok": false,
      "moderation_required": false,
      "data_policy": {
        "termsOfServiceURL": "https://www.parasail.io/legal/terms",
        "privacyPolicyURL": "https://www.parasail.io/legal/privacy-policy",
        "paidModels": {
          "training": false,
          "retainsPrompts": true
        },
        "training": false,
        "retainsPrompts": true
      },
      "pricing": {
        "prompt": "0.00000009",
        "completion": "0.00000048",
        "image": "0.00046788",
        "request": "0",
        "web_search": "0",
        "internal_reasoning": "0",
        "discount": 0
      },
      "variable_pricings": [],
      "is_hidden": false,
      "is_deranked": false,
      "is_disabled": false,
      "supports_tool_parameters": false,
      "supports_reasoning": false,
      "supports_multipart": true,
      "limit_rpm": null,
      "limit_rpd": null,
      "limit_rpm_cf": null,
      "has_completions": true,
      "has_chat_completions": true,
      "features": {
        "supported_parameters": {},
        "supports_document_url": null
      },
      "provider_region": null,
      "stats": {
        "endpoint_id": "1ef8e974-2a93-42d6-9eca-bff18a57e595",
        "p50_throughput": 98.3235,
        "p50_latency": 450.5,
        "request_count": 34787
      },
      "status": 0
    },
    {
      "id": "87de9966-52ce-415b-94b9-cb1809d23aff",
      "name": "Cent-ML | meta-llama/llama-4-scout-17b-16e-instruct",
      "context_length": 1048576,
      "model": {
        "slug": "meta-llama/llama-4-scout",
        "hf_slug": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "updated_at": "2025-05-16T21:16:57.919461+00:00",
        "created_at": "2025-04-05T19:31:59.735804+00:00",
        "hf_updated_at": null,
        "name": "Meta: Llama 4 Scout",
        "short_name": "Llama 4 Scout",
        "author": "meta-llama",
        "description": "Llama 4 Scout 17B Instruct (16E) is a mixture-of-experts (MoE) language model developed by Meta, activating 17 billion parameters out of a total of 109B. It supports native multimodal input (text and image) and multilingual output (text and code) across 12 supported languages. Designed for assistant-style interaction and visual reasoning, Scout uses 16 experts per forward pass and features a context length of 10 million tokens, with a training corpus of ~40 trillion tokens.\n\nBuilt for high efficiency and local or commercial deployment, Llama 4 Scout incorporates early fusion for seamless modality integration. It is instruction-tuned for use in multilingual chat, captioning, and image understanding tasks. Released under the Llama 4 Community License, it was last trained on data up to August 2024 and launched publicly on April 5, 2025.",
        "model_version_group_id": null,
        "context_length": 10000000,
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "has_text_output": true,
        "group": "Llama4",
        "instruct_type": null,
        "default_system": null,
        "default_stops": [],
        "hidden": false,
        "router": null,
        "warning_message": null,
        "permaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
        "reasoning_config": null,
        "features": {}
      },
      "model_variant_slug": "meta-llama/llama-4-scout",
      "model_variant_permaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
      "provider_name": "Cent-ML",
      "provider_info": {
        "name": "Cent-ML",
        "displayName": "CentML",
        "slug": "centml",
        "baseUrl": "url",
        "dataPolicy": {
          "termsOfServiceURL": "https://centml.ai/terms-of-service/",
          "privacyPolicyURL": "https://centml.ai/privacy-policy/",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          }
        },
        "headquarters": "CA",
        "hasChatCompletions": true,
        "hasCompletions": true,
        "isAbortable": true,
        "moderationRequired": false,
        "editors": [],
        "owners": [],
        "isMultipartSupported": true,
        "statusPageUrl": null,
        "byokEnabled": true,
        "icon": {
          "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://centml.ai/&size=256"
        }
      },
      "provider_display_name": "CentML",
      "provider_model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "quantization": "bf16",
      "variant": "standard",
      "is_free": false,
      "can_abort": true,
      "max_prompt_tokens": null,
      "max_completion_tokens": 1048576,
      "max_prompt_images": null,
      "max_tokens_per_image": null,
      "supported_parameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "top_k",
        "min_p",
        "repetition_penalty"
      ],
      "is_byok": false,
      "moderation_required": false,
      "data_policy": {
        "termsOfServiceURL": "https://centml.ai/terms-of-service/",
        "privacyPolicyURL": "https://centml.ai/privacy-policy/",
        "paidModels": {
          "training": false,
          "retainsPrompts": false
        },
        "training": false,
        "retainsPrompts": false
      },
      "pricing": {
        "prompt": "0.0000001",
        "completion": "0.0000001",
        "image": "0",
        "request": "0",
        "web_search": "0",
        "internal_reasoning": "0",
        "discount": 0
      },
      "variable_pricings": [],
      "is_hidden": false,
      "is_deranked": false,
      "is_disabled": false,
      "supports_tool_parameters": false,
      "supports_reasoning": false,
      "supports_multipart": true,
      "limit_rpm": null,
      "limit_rpd": null,
      "limit_rpm_cf": null,
      "has_completions": true,
      "has_chat_completions": true,
      "features": {
        "supported_parameters": {},
        "supports_document_url": null
      },
      "provider_region": null,
      "stats": {
        "endpoint_id": "87de9966-52ce-415b-94b9-cb1809d23aff",
        "p50_throughput": 84.025,
        "p50_latency": 320,
        "request_count": 50322
      },
      "status": 0
    },
    {
      "id": "b0352c4a-a51c-4ee0-9f5e-cfa527c3a208",
      "name": "Novita | meta-llama/llama-4-scout-17b-16e-instruct",
      "context_length": 131072,
      "model": {
        "slug": "meta-llama/llama-4-scout",
        "hf_slug": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "updated_at": "2025-05-16T21:16:57.919461+00:00",
        "created_at": "2025-04-05T19:31:59.735804+00:00",
        "hf_updated_at": null,
        "name": "Meta: Llama 4 Scout",
        "short_name": "Llama 4 Scout",
        "author": "meta-llama",
        "description": "Llama 4 Scout 17B Instruct (16E) is a mixture-of-experts (MoE) language model developed by Meta, activating 17 billion parameters out of a total of 109B. It supports native multimodal input (text and image) and multilingual output (text and code) across 12 supported languages. Designed for assistant-style interaction and visual reasoning, Scout uses 16 experts per forward pass and features a context length of 10 million tokens, with a training corpus of ~40 trillion tokens.\n\nBuilt for high efficiency and local or commercial deployment, Llama 4 Scout incorporates early fusion for seamless modality integration. It is instruction-tuned for use in multilingual chat, captioning, and image understanding tasks. Released under the Llama 4 Community License, it was last trained on data up to August 2024 and launched publicly on April 5, 2025.",
        "model_version_group_id": null,
        "context_length": 10000000,
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "has_text_output": true,
        "group": "Llama4",
        "instruct_type": null,
        "default_system": null,
        "default_stops": [],
        "hidden": false,
        "router": null,
        "warning_message": null,
        "permaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
        "reasoning_config": null,
        "features": {}
      },
      "model_variant_slug": "meta-llama/llama-4-scout",
      "model_variant_permaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
      "provider_name": "Novita",
      "provider_info": {
        "name": "Novita",
        "displayName": "NovitaAI",
        "slug": "novita",
        "baseUrl": "url",
        "dataPolicy": {
          "termsOfServiceURL": "https://novita.ai/legal/terms-of-service",
          "privacyPolicyURL": "https://novita.ai/legal/privacy-policy",
          "paidModels": {
            "training": false
          }
        },
        "headquarters": "US",
        "hasChatCompletions": true,
        "hasCompletions": true,
        "isAbortable": true,
        "moderationRequired": false,
        "editors": [],
        "owners": [],
        "isMultipartSupported": true,
        "statusPageUrl": "https://status.novita.ai/",
        "byokEnabled": true,
        "icon": {
          "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://novita.ai/&size=256",
          "invertRequired": true
        }
      },
      "provider_display_name": "NovitaAI",
      "provider_model_id": "meta-llama/llama-4-scout-17b-16e-instruct",
      "quantization": null,
      "variant": "standard",
      "is_free": false,
      "can_abort": true,
      "max_prompt_tokens": null,
      "max_completion_tokens": 131072,
      "max_prompt_images": 1,
      "max_tokens_per_image": null,
      "supported_parameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "seed",
        "top_k",
        "min_p",
        "repetition_penalty",
        "logit_bias"
      ],
      "is_byok": false,
      "moderation_required": false,
      "data_policy": {
        "termsOfServiceURL": "https://novita.ai/legal/terms-of-service",
        "privacyPolicyURL": "https://novita.ai/legal/privacy-policy",
        "paidModels": {
          "training": false
        },
        "training": false
      },
      "pricing": {
        "prompt": "0.0000001",
        "completion": "0.0000005",
        "image": "0.0003342",
        "request": "0",
        "web_search": "0",
        "internal_reasoning": "0",
        "discount": 0
      },
      "variable_pricings": [],
      "is_hidden": false,
      "is_deranked": false,
      "is_disabled": false,
      "supports_tool_parameters": false,
      "supports_reasoning": false,
      "supports_multipart": true,
      "limit_rpm": null,
      "limit_rpd": null,
      "limit_rpm_cf": null,
      "has_completions": true,
      "has_chat_completions": true,
      "features": {
        "supported_parameters": {},
        "supports_document_url": null
      },
      "provider_region": null,
      "stats": {
        "endpoint_id": "b0352c4a-a51c-4ee0-9f5e-cfa527c3a208",
        "p50_throughput": 48.192,
        "p50_latency": 998.5,
        "request_count": 27463
      },
      "status": 0
    },
    {
      "id": "c65a0343-4d7c-4c34-b665-2bddd8cb8431",
      "name": "Groq | meta-llama/llama-4-scout-17b-16e-instruct",
      "context_length": 131072,
      "model": {
        "slug": "meta-llama/llama-4-scout",
        "hf_slug": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "updated_at": "2025-05-16T21:16:57.919461+00:00",
        "created_at": "2025-04-05T19:31:59.735804+00:00",
        "hf_updated_at": null,
        "name": "Meta: Llama 4 Scout",
        "short_name": "Llama 4 Scout",
        "author": "meta-llama",
        "description": "Llama 4 Scout 17B Instruct (16E) is a mixture-of-experts (MoE) language model developed by Meta, activating 17 billion parameters out of a total of 109B. It supports native multimodal input (text and image) and multilingual output (text and code) across 12 supported languages. Designed for assistant-style interaction and visual reasoning, Scout uses 16 experts per forward pass and features a context length of 10 million tokens, with a training corpus of ~40 trillion tokens.\n\nBuilt for high efficiency and local or commercial deployment, Llama 4 Scout incorporates early fusion for seamless modality integration. It is instruction-tuned for use in multilingual chat, captioning, and image understanding tasks. Released under the Llama 4 Community License, it was last trained on data up to August 2024 and launched publicly on April 5, 2025.",
        "model_version_group_id": null,
        "context_length": 10000000,
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "has_text_output": true,
        "group": "Llama4",
        "instruct_type": null,
        "default_system": null,
        "default_stops": [],
        "hidden": false,
        "router": null,
        "warning_message": null,
        "permaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
        "reasoning_config": null,
        "features": {}
      },
      "model_variant_slug": "meta-llama/llama-4-scout",
      "model_variant_permaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
      "provider_name": "Groq",
      "provider_info": {
        "name": "Groq",
        "displayName": "Groq",
        "slug": "groq",
        "baseUrl": "url",
        "dataPolicy": {
          "termsOfServiceURL": "https://groq.com/terms-of-use/",
          "privacyPolicyURL": "https://groq.com/privacy-policy/",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          }
        },
        "headquarters": "US",
        "hasChatCompletions": true,
        "hasCompletions": false,
        "isAbortable": false,
        "moderationRequired": false,
        "editors": [],
        "owners": [],
        "isMultipartSupported": true,
        "statusPageUrl": null,
        "byokEnabled": true,
        "icon": {
          "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://groq.com/&size=256"
        }
      },
      "provider_display_name": "Groq",
      "provider_model_id": "meta-llama/llama-4-scout-17b-16e-instruct",
      "quantization": null,
      "variant": "standard",
      "is_free": false,
      "can_abort": false,
      "max_prompt_tokens": null,
      "max_completion_tokens": 8192,
      "max_prompt_images": null,
      "max_tokens_per_image": null,
      "supported_parameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "response_format",
        "top_logprobs",
        "logprobs",
        "logit_bias",
        "seed"
      ],
      "is_byok": false,
      "moderation_required": false,
      "data_policy": {
        "termsOfServiceURL": "https://groq.com/terms-of-use/",
        "privacyPolicyURL": "https://groq.com/privacy-policy/",
        "paidModels": {
          "training": false,
          "retainsPrompts": false
        },
        "training": false,
        "retainsPrompts": false
      },
      "pricing": {
        "prompt": "0.00000011",
        "completion": "0.00000034",
        "image": "0.00036762",
        "request": "0",
        "web_search": "0",
        "internal_reasoning": "0",
        "discount": 0
      },
      "variable_pricings": [],
      "is_hidden": false,
      "is_deranked": false,
      "is_disabled": false,
      "supports_tool_parameters": true,
      "supports_reasoning": false,
      "supports_multipart": true,
      "limit_rpm": null,
      "limit_rpd": null,
      "limit_rpm_cf": null,
      "has_completions": false,
      "has_chat_completions": true,
      "features": {
        "supported_parameters": {},
        "supports_document_url": null
      },
      "provider_region": null,
      "stats": {
        "endpoint_id": "c65a0343-4d7c-4c34-b665-2bddd8cb8431",
        "p50_throughput": 669.1785,
        "p50_latency": 456,
        "request_count": 35353
      },
      "status": 0
    },
    {
      "id": "0cb1e570-c6b7-41ce-a0c0-81f6a56d9848",
      "name": "Fireworks | meta-llama/llama-4-scout-17b-16e-instruct",
      "context_length": 1048576,
      "model": {
        "slug": "meta-llama/llama-4-scout",
        "hf_slug": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "updated_at": "2025-05-16T21:16:57.919461+00:00",
        "created_at": "2025-04-05T19:31:59.735804+00:00",
        "hf_updated_at": null,
        "name": "Meta: Llama 4 Scout",
        "short_name": "Llama 4 Scout",
        "author": "meta-llama",
        "description": "Llama 4 Scout 17B Instruct (16E) is a mixture-of-experts (MoE) language model developed by Meta, activating 17 billion parameters out of a total of 109B. It supports native multimodal input (text and image) and multilingual output (text and code) across 12 supported languages. Designed for assistant-style interaction and visual reasoning, Scout uses 16 experts per forward pass and features a context length of 10 million tokens, with a training corpus of ~40 trillion tokens.\n\nBuilt for high efficiency and local or commercial deployment, Llama 4 Scout incorporates early fusion for seamless modality integration. It is instruction-tuned for use in multilingual chat, captioning, and image understanding tasks. Released under the Llama 4 Community License, it was last trained on data up to August 2024 and launched publicly on April 5, 2025.",
        "model_version_group_id": null,
        "context_length": 10000000,
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "has_text_output": true,
        "group": "Llama4",
        "instruct_type": null,
        "default_system": null,
        "default_stops": [],
        "hidden": false,
        "router": null,
        "warning_message": null,
        "permaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
        "reasoning_config": null,
        "features": {}
      },
      "model_variant_slug": "meta-llama/llama-4-scout",
      "model_variant_permaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
      "provider_name": "Fireworks",
      "provider_info": {
        "name": "Fireworks",
        "displayName": "Fireworks",
        "slug": "fireworks",
        "baseUrl": "url",
        "dataPolicy": {
          "termsOfServiceURL": "https://fireworks.ai/terms-of-service",
          "privacyPolicyURL": "https://fireworks.ai/privacy-policy",
          "dataPolicyUrl": "https://docs.fireworks.ai/guides/security_compliance/data_handling",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          }
        },
        "headquarters": "US",
        "hasChatCompletions": true,
        "hasCompletions": true,
        "isAbortable": true,
        "moderationRequired": false,
        "editors": [],
        "owners": [],
        "isMultipartSupported": true,
        "statusPageUrl": "https://status.fireworks.ai/",
        "byokEnabled": true,
        "icon": {
          "url": "/images/icons/Fireworks.png"
        }
      },
      "provider_display_name": "Fireworks",
      "provider_model_id": "accounts/fireworks/models/llama4-scout-instruct-basic",
      "quantization": null,
      "variant": "standard",
      "is_free": false,
      "can_abort": true,
      "max_prompt_tokens": null,
      "max_completion_tokens": null,
      "max_prompt_images": null,
      "max_tokens_per_image": null,
      "supported_parameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "top_k",
        "repetition_penalty",
        "response_format",
        "structured_outputs",
        "logit_bias",
        "logprobs",
        "top_logprobs"
      ],
      "is_byok": false,
      "moderation_required": false,
      "data_policy": {
        "termsOfServiceURL": "https://fireworks.ai/terms-of-service",
        "privacyPolicyURL": "https://fireworks.ai/privacy-policy",
        "dataPolicyUrl": "https://docs.fireworks.ai/guides/security_compliance/data_handling",
        "paidModels": {
          "training": false,
          "retainsPrompts": false
        },
        "training": false,
        "retainsPrompts": false
      },
      "pricing": {
        "prompt": "0.00000015",
        "completion": "0.0000006",
        "image": "0",
        "request": "0",
        "web_search": "0",
        "internal_reasoning": "0",
        "discount": 0
      },
      "variable_pricings": [],
      "is_hidden": false,
      "is_deranked": false,
      "is_disabled": false,
      "supports_tool_parameters": true,
      "supports_reasoning": false,
      "supports_multipart": true,
      "limit_rpm": null,
      "limit_rpd": null,
      "limit_rpm_cf": null,
      "has_completions": true,
      "has_chat_completions": true,
      "features": {
        "supported_parameters": {},
        "supports_document_url": null
      },
      "provider_region": null,
      "stats": {
        "endpoint_id": "0cb1e570-c6b7-41ce-a0c0-81f6a56d9848",
        "p50_throughput": 97.909,
        "p50_latency": 546,
        "request_count": 15376
      },
      "status": 0
    },
    {
      "id": "1a170f0e-82d1-45c9-8acb-293a56dadbb8",
      "name": "GMICloud | meta-llama/llama-4-scout-17b-16e-instruct",
      "context_length": 1048576,
      "model": {
        "slug": "meta-llama/llama-4-scout",
        "hf_slug": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "updated_at": "2025-05-16T21:16:57.919461+00:00",
        "created_at": "2025-04-05T19:31:59.735804+00:00",
        "hf_updated_at": null,
        "name": "Meta: Llama 4 Scout",
        "short_name": "Llama 4 Scout",
        "author": "meta-llama",
        "description": "Llama 4 Scout 17B Instruct (16E) is a mixture-of-experts (MoE) language model developed by Meta, activating 17 billion parameters out of a total of 109B. It supports native multimodal input (text and image) and multilingual output (text and code) across 12 supported languages. Designed for assistant-style interaction and visual reasoning, Scout uses 16 experts per forward pass and features a context length of 10 million tokens, with a training corpus of ~40 trillion tokens.\n\nBuilt for high efficiency and local or commercial deployment, Llama 4 Scout incorporates early fusion for seamless modality integration. It is instruction-tuned for use in multilingual chat, captioning, and image understanding tasks. Released under the Llama 4 Community License, it was last trained on data up to August 2024 and launched publicly on April 5, 2025.",
        "model_version_group_id": null,
        "context_length": 10000000,
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "has_text_output": true,
        "group": "Llama4",
        "instruct_type": null,
        "default_system": null,
        "default_stops": [],
        "hidden": false,
        "router": null,
        "warning_message": null,
        "permaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
        "reasoning_config": null,
        "features": {}
      },
      "model_variant_slug": "meta-llama/llama-4-scout",
      "model_variant_permaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
      "provider_name": "GMICloud",
      "provider_info": {
        "name": "GMICloud",
        "displayName": "GMICloud",
        "slug": "gmicloud",
        "baseUrl": "url",
        "dataPolicy": {
          "privacyPolicyURL": "https://docs.gmicloud.ai/privacy",
          "paidModels": {
            "training": false
          }
        },
        "hasChatCompletions": true,
        "hasCompletions": true,
        "isAbortable": true,
        "moderationRequired": false,
        "editors": [],
        "owners": [],
        "isMultipartSupported": true,
        "statusPageUrl": null,
        "byokEnabled": true,
        "icon": {
          "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://gmicloud.ai/&size=256",
          "invertRequired": true
        }
      },
      "provider_display_name": "GMICloud",
      "provider_model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "quantization": "bf16",
      "variant": "standard",
      "is_free": false,
      "can_abort": true,
      "max_prompt_tokens": null,
      "max_completion_tokens": null,
      "max_prompt_images": null,
      "max_tokens_per_image": null,
      "supported_parameters": [
        "max_tokens",
        "temperature",
        "top_p",
        "seed"
      ],
      "is_byok": false,
      "moderation_required": false,
      "data_policy": {
        "privacyPolicyURL": "https://docs.gmicloud.ai/privacy",
        "paidModels": {
          "training": false
        },
        "training": false
      },
      "pricing": {
        "prompt": "0.00000015",
        "completion": "0.0000006",
        "image": "0",
        "request": "0",
        "web_search": "0",
        "internal_reasoning": "0",
        "discount": 0
      },
      "variable_pricings": [],
      "is_hidden": false,
      "is_deranked": false,
      "is_disabled": false,
      "supports_tool_parameters": false,
      "supports_reasoning": false,
      "supports_multipart": true,
      "limit_rpm": null,
      "limit_rpd": null,
      "limit_rpm_cf": null,
      "has_completions": true,
      "has_chat_completions": true,
      "features": {
        "supported_parameters": {},
        "supports_document_url": null
      },
      "provider_region": null,
      "stats": {
        "endpoint_id": "1a170f0e-82d1-45c9-8acb-293a56dadbb8",
        "p50_throughput": 103.9925,
        "p50_latency": 806,
        "request_count": 13139
      },
      "status": 0
    },
    {
      "id": "24fa6d0d-b679-4e6d-8c94-b7581400ec92",
      "name": "Together | meta-llama/llama-4-scout-17b-16e-instruct",
      "context_length": 1048576,
      "model": {
        "slug": "meta-llama/llama-4-scout",
        "hf_slug": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "updated_at": "2025-05-16T21:16:57.919461+00:00",
        "created_at": "2025-04-05T19:31:59.735804+00:00",
        "hf_updated_at": null,
        "name": "Meta: Llama 4 Scout",
        "short_name": "Llama 4 Scout",
        "author": "meta-llama",
        "description": "Llama 4 Scout 17B Instruct (16E) is a mixture-of-experts (MoE) language model developed by Meta, activating 17 billion parameters out of a total of 109B. It supports native multimodal input (text and image) and multilingual output (text and code) across 12 supported languages. Designed for assistant-style interaction and visual reasoning, Scout uses 16 experts per forward pass and features a context length of 10 million tokens, with a training corpus of ~40 trillion tokens.\n\nBuilt for high efficiency and local or commercial deployment, Llama 4 Scout incorporates early fusion for seamless modality integration. It is instruction-tuned for use in multilingual chat, captioning, and image understanding tasks. Released under the Llama 4 Community License, it was last trained on data up to August 2024 and launched publicly on April 5, 2025.",
        "model_version_group_id": null,
        "context_length": 10000000,
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "has_text_output": true,
        "group": "Llama4",
        "instruct_type": null,
        "default_system": null,
        "default_stops": [],
        "hidden": false,
        "router": null,
        "warning_message": null,
        "permaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
        "reasoning_config": null,
        "features": {}
      },
      "model_variant_slug": "meta-llama/llama-4-scout",
      "model_variant_permaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
      "provider_name": "Together",
      "provider_info": {
        "name": "Together",
        "displayName": "Together",
        "slug": "together",
        "baseUrl": "url",
        "dataPolicy": {
          "termsOfServiceURL": "https://www.together.ai/terms-of-service",
          "privacyPolicyURL": "https://www.together.ai/privacy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          }
        },
        "headquarters": "US",
        "hasChatCompletions": true,
        "hasCompletions": true,
        "isAbortable": true,
        "moderationRequired": false,
        "editors": [],
        "owners": [],
        "isMultipartSupported": true,
        "statusPageUrl": null,
        "byokEnabled": true,
        "icon": {
          "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.together.ai/&size=256"
        }
      },
      "provider_display_name": "Together",
      "provider_model_id": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
      "quantization": null,
      "variant": "standard",
      "is_free": false,
      "can_abort": true,
      "max_prompt_tokens": null,
      "max_completion_tokens": null,
      "max_prompt_images": null,
      "max_tokens_per_image": null,
      "supported_parameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "stop",
        "frequency_penalty",
        "presence_penalty",
        "top_k",
        "repetition_penalty",
        "logit_bias",
        "min_p",
        "response_format"
      ],
      "is_byok": false,
      "moderation_required": false,
      "data_policy": {
        "termsOfServiceURL": "https://www.together.ai/terms-of-service",
        "privacyPolicyURL": "https://www.together.ai/privacy",
        "paidModels": {
          "training": false,
          "retainsPrompts": false
        },
        "training": false,
        "retainsPrompts": false
      },
      "pricing": {
        "prompt": "0.00000018",
        "completion": "0.00000059",
        "image": "0.00090234",
        "request": "0",
        "web_search": "0",
        "internal_reasoning": "0",
        "discount": 0
      },
      "variable_pricings": [],
      "is_hidden": false,
      "is_deranked": false,
      "is_disabled": false,
      "supports_tool_parameters": true,
      "supports_reasoning": false,
      "supports_multipart": true,
      "limit_rpm": null,
      "limit_rpd": null,
      "limit_rpm_cf": null,
      "has_completions": true,
      "has_chat_completions": true,
      "features": {
        "supported_parameters": {},
        "supports_document_url": null
      },
      "provider_region": null,
      "stats": {
        "endpoint_id": "24fa6d0d-b679-4e6d-8c94-b7581400ec92",
        "p50_throughput": 104.088,
        "p50_latency": 395,
        "request_count": 10872
      },
      "status": 0
    },
    {
      "id": "b472f5ad-9135-4171-8042-53ddc9664dd9",
      "name": "Cerebras | meta-llama/llama-4-scout-17b-16e-instruct",
      "context_length": 32000,
      "model": {
        "slug": "meta-llama/llama-4-scout",
        "hf_slug": "meta-llama/Llama-4-Scout-17B-16E-Instruct",
        "updated_at": "2025-05-16T21:16:57.919461+00:00",
        "created_at": "2025-04-05T19:31:59.735804+00:00",
        "hf_updated_at": null,
        "name": "Meta: Llama 4 Scout",
        "short_name": "Llama 4 Scout",
        "author": "meta-llama",
        "description": "Llama 4 Scout 17B Instruct (16E) is a mixture-of-experts (MoE) language model developed by Meta, activating 17 billion parameters out of a total of 109B. It supports native multimodal input (text and image) and multilingual output (text and code) across 12 supported languages. Designed for assistant-style interaction and visual reasoning, Scout uses 16 experts per forward pass and features a context length of 10 million tokens, with a training corpus of ~40 trillion tokens.\n\nBuilt for high efficiency and local or commercial deployment, Llama 4 Scout incorporates early fusion for seamless modality integration. It is instruction-tuned for use in multilingual chat, captioning, and image understanding tasks. Released under the Llama 4 Community License, it was last trained on data up to August 2024 and launched publicly on April 5, 2025.",
        "model_version_group_id": null,
        "context_length": 10000000,
        "input_modalities": [
          "text",
          "image"
        ],
        "output_modalities": [
          "text"
        ],
        "has_text_output": true,
        "group": "Llama4",
        "instruct_type": null,
        "default_system": null,
        "default_stops": [],
        "hidden": false,
        "router": null,
        "warning_message": null,
        "permaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
        "reasoning_config": null,
        "features": {}
      },
      "model_variant_slug": "meta-llama/llama-4-scout",
      "model_variant_permaslug": "meta-llama/llama-4-scout-17b-16e-instruct",
      "provider_name": "Cerebras",
      "provider_info": {
        "name": "Cerebras",
        "displayName": "Cerebras",
        "slug": "cerebras",
        "baseUrl": "url",
        "dataPolicy": {
          "termsOfServiceURL": "https://www.cerebras.ai/terms-of-service",
          "privacyPolicyURL": "https://www.cerebras.ai/privacy-policy",
          "paidModels": {
            "training": false,
            "retainsPrompts": false
          }
        },
        "headquarters": "US",
        "hasChatCompletions": true,
        "hasCompletions": true,
        "isAbortable": true,
        "moderationRequired": false,
        "editors": [],
        "owners": [],
        "isMultipartSupported": false,
        "statusPageUrl": null,
        "byokEnabled": true,
        "icon": {
          "url": "https://t0.gstatic.com/faviconV2?client=SOCIAL&type=FAVICON&fallback_opts=TYPE,SIZE,URL&url=https://www.cerebras.ai/&size=256"
        }
      },
      "provider_display_name": "Cerebras",
      "provider_model_id": "llama-4-scout-17b-16e-instruct",
      "quantization": null,
      "variant": "standard",
      "is_free": false,
      "can_abort": true,
      "max_prompt_tokens": null,
      "max_completion_tokens": 32000,
      "max_prompt_images": null,
      "max_tokens_per_image": null,
      "supported_parameters": [
        "tools",
        "tool_choice",
        "max_tokens",
        "temperature",
        "top_p",
        "structured_outputs",
        "response_format",
        "stop",
        "seed",
        "logprobs",
        "top_logprobs"
      ],
      "is_byok": false,
      "moderation_required": false,
      "data_policy": {
        "termsOfServiceURL": "https://www.cerebras.ai/terms-of-service",
        "privacyPolicyURL": "https://www.cerebras.ai/privacy-policy",
        "paidModels": {
          "training": false,
          "retainsPrompts": false
        },
        "training": false,
        "retainsPrompts": false
      },
      "pricing": {
        "prompt": "0.00000065",
        "completion": "0.00000085",
        "image": "0",
        "request": "0",
        "web_search": "0",
        "internal_reasoning": "0",
        "discount": 0
      },
      "variable_pricings": [],
      "is_hidden": false,
      "is_deranked": false,
      "is_disabled": false,
      "supports_tool_parameters": true,
      "supports_reasoning": false,
      "supports_multipart": false,
      "limit_rpm": null,
      "limit_rpd": null,
      "limit_rpm_cf": null,
      "has_completions": true,
      "has_chat_completions": true,
      "features": {
        "supported_parameters": {
          "response_format": true,
          "structured_outputs": true
        },
        "supports_document_url": null
      },
      "provider_region": null,
      "stats": {
        "endpoint_id": "b472f5ad-9135-4171-8042-53ddc9664dd9",
        "p50_throughput": 5946.4235,
        "p50_latency": 373,
        "request_count": 9466
      },
      "status": 0
    }
  ]
}